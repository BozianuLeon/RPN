{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): AdaptiveAvgPool2d(output_size=(128, 128))\n",
      ")\n",
      "torch.Size([100, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "#vgg16_model=models.vgg16(pretrained=True)\n",
    "vgg16_model = models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "modules=list(vgg16_model.children())[:-2]\n",
    "modules = modules + [torch.nn.Conv2d(in_channels=512,out_channels=64,kernel_size=3,stride=1,padding=1),torch.nn.ReLU(inplace=True),torch.nn.AdaptiveAvgPool2d(output_size=(128, 128))]\n",
    "vgg16_model=nn.Sequential(*modules)\n",
    "print(vgg16_model)\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "features_var=vgg16_model(img)\n",
    "features=features_var.data\n",
    "features=features.data\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-3])\n",
    "print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-2])\n",
    "print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "modules=list(vgg16_model.children())[:-2]\n",
    "modules = modules + [torch.nn.Conv2d(in_channels=512,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "                     torch.nn.ReLU(inplace=True),\n",
    "                     torch.nn.AdaptiveAvgPool2d(output_size=(128, 128)),\n",
    "                    ]\n",
    "\n",
    "vgg16_model=torch.nn.Sequential(*modules)\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "features = vgg16_model(img)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([100, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class SharedConvolutionalLayers(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,48,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(48,128,kernel_size=3,stride=2,padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(128,out_channels,kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        shared_output = []\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.relu(self.conv3(x))\n",
    "\n",
    "        shared_output.append(x)\n",
    "\n",
    "        return shared_output\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "mmodel = SharedConvolutionalLayers(128)\n",
    "features = mmodel(img)\n",
    "\n",
    "print(len(features))\n",
    "print(features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([100, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class SharedConvLayersVGG(nn.Module):\n",
    "    def __init__(self,out_channels,out_size=64):\n",
    "        super().__init__()\n",
    "        vgg16_back = torchvision.models.vgg16(weights=\"VGG16_Weights.DEFAULT\")\n",
    "        modules = list(vgg16_back.children())[:-2]\n",
    "        module_list = modules + [torch.nn.Conv2d(in_channels=512,out_channels=out_channels,kernel_size=3,stride=1,padding=1),\n",
    "                                 torch.nn.ReLU(inplace=True),\n",
    "                                 torch.nn.AdaptiveAvgPool2d(output_size=(out_size, out_size))]\n",
    "        self.share_conv_layers = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self,x):\n",
    "        shared_output = []\n",
    "        out = self.share_conv_layers(x)\n",
    "        shared_output.append(out)\n",
    "        return shared_output\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "model2 = SharedConvLayersVGG(128)\n",
    "features2 = model2(img)\n",
    "\n",
    "print(len(features2))\n",
    "print(features2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([100, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class SharedConvLayersVGG(nn.Module):\n",
    "    def __init__(self,out_channels,out_size=64):\n",
    "        super().__init__()\n",
    "        vgg16 = torchvision.models.vgg16(weights=\"VGG16_Weights.DEFAULT\").requires_grad_(False)\n",
    "        modules = list(vgg16.children())[:-2]\n",
    "        self.vgg16_back = nn.Sequential(*modules)\n",
    "\n",
    "        module_list = [torch.nn.Conv2d(in_channels=512,out_channels=out_channels,kernel_size=3,stride=1,padding=1),\n",
    "                       torch.nn.ReLU(inplace=True),\n",
    "                       torch.nn.AdaptiveAvgPool2d(output_size=(out_size, out_size))]\n",
    "        self.share_conv_layers = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self,x):\n",
    "        shared_output = []\n",
    "        h = self.vgg16_back(x)\n",
    "        out = self.share_conv_layers(h)\n",
    "        shared_output.append(out)\n",
    "        return shared_output\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "model2 = SharedConvLayersVGG(128)\n",
    "features2 = model2(img)\n",
    "\n",
    "print(len(features2))\n",
    "print(features2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.randn((8,3,128,128))\n",
    "ll = []\n",
    "for feature in img_tensor:\n",
    "    h = torch.nn.Conv2d(3,24,kernel_size=3,padding=0,stride=3)(feature)\n",
    "    ll.append(h)\n",
    "print(len(ll),ll[0].shape)\n",
    "alter = torch.stack(ll,dim=0)\n",
    "print(len(alter))\n",
    "print()\n",
    "\n",
    "out = vgg16_model(img_tensor)\n",
    "print(out.shape)\n",
    "alter2 = [out]\n",
    "print(len(alter2))\n",
    "print(alter2[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d27589028232142a787c3462b4b279b1d69c1663af8ab078284397c88ed6c3de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
