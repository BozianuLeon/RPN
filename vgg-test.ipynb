{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freezing weights\n",
    "#https://gist.github.com/L0SG/2f6d81e4ad119c4f798ab81fa8d62d3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): AdaptiveAvgPool2d(output_size=(128, 128))\n",
      ")\n",
      "torch.Size([100, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "#vgg16_model=models.vgg16(pretrained=True)\n",
    "vgg16_model = models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "modules=list(vgg16_model.children())[:-2]\n",
    "modules = modules + [torch.nn.Conv2d(in_channels=512,out_channels=64,kernel_size=3,stride=1,padding=1),torch.nn.ReLU(inplace=True),torch.nn.AdaptiveAvgPool2d(output_size=(128, 128))]\n",
    "vgg16_model=nn.Sequential(*modules)\n",
    "print(vgg16_model)\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "features_var=vgg16_model(img)\n",
    "features=features_var.data\n",
    "features=features.data\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 7])\n",
      "16384\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "input = torch.randn(1, 3, 256, 256)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "print(128*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-3])\n",
    "print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-2])\n",
    "print(list(models.vgg16(weights='VGG16_Weights.DEFAULT').children())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m modules\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(vgg16_model\u001b[39m.\u001b[39mchildren())[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m      3\u001b[0m modules \u001b[39m=\u001b[39m modules \u001b[39m+\u001b[39m [torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mConv2d(in_channels\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,out_channels\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m      4\u001b[0m                      torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m                      torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mAdaptiveAvgPool2d(output_size\u001b[39m=\u001b[39m(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)),\n\u001b[1;32m      6\u001b[0m                      []]\n\u001b[0;32m----> 8\u001b[0m vgg16_model\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mSequential(\u001b[39m*\u001b[39;49mmodules)\n\u001b[1;32m     10\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m100\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m))\n\u001b[1;32m     11\u001b[0m features \u001b[39m=\u001b[39m vgg16_model(img)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:91\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[39mfor\u001b[39;00m idx, module \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(args):\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_module(\u001b[39mstr\u001b[39;49m(idx), module)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:444\u001b[0m, in \u001b[0;36mModule.add_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Adds a child module to the current module.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[39mThe module can be accessed as an attribute using the given name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39m    module (Module): child module to be added to the module.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(module, Module) \u001b[39mand\u001b[39;00m module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not a Module subclass\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    445\u001b[0m         torch\u001b[39m.\u001b[39mtypename(module)))\n\u001b[1;32m    446\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(name, torch\u001b[39m.\u001b[39m_six\u001b[39m.\u001b[39mstring_classes):\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule name should be a string. Got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    448\u001b[0m         torch\u001b[39m.\u001b[39mtypename(name)))\n",
      "\u001b[0;31mTypeError\u001b[0m: list is not a Module subclass"
     ]
    }
   ],
   "source": [
    "vgg16_model = models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "modules=list(vgg16_model.children())[:-2]\n",
    "modules = modules + [torch.nn.Conv2d(in_channels=512,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "                     torch.nn.ReLU(inplace=True),\n",
    "                     torch.nn.AdaptiveAvgPool2d(output_size=(128, 128)),\n",
    "                     []]\n",
    "\n",
    "vgg16_model=torch.nn.Sequential(*modules)\n",
    "\n",
    "img = torch.randn((100,3,256,256))\n",
    "features = vgg16_model(img)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.randn((8,3,128,128))\n",
    "ll = []\n",
    "for feature in img_tensor:\n",
    "    h = torch.nn.Conv2d(3,24,kernel_size=3,padding=0,stride=3)(feature)\n",
    "    ll.append(h)\n",
    "print(len(ll),ll[0].shape)\n",
    "alter = torch.stack(ll,dim=0)\n",
    "print(len(alter))\n",
    "print()\n",
    "\n",
    "out = vgg16_model(img_tensor)\n",
    "print(out.shape)\n",
    "alter2 = [out]\n",
    "print(len(alter2))\n",
    "print(alter2[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d27589028232142a787c3462b4b279b1d69c1663af8ab078284397c88ed6c3de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
